# -*- coding: utf-8 -*-
"""Final_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_mpUNcdSwQMF1HrdhsQtgazMwAQjLoB
"""

import torch

print("CUDA Available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))

from google.colab import drive
drive.mount('/content/drive')

!pip install torch torchvision tqdm

import os
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

class Pix2PixDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
        self.image_filenames = [f for f in os.listdir(image_dir) if f.lower().endswith(valid_extensions)]

        print(f"Found {len(self.image_filenames)} images in '{image_dir}'")

        if len(self.image_filenames) == 0:
            raise ValueError(f"No images found in directory: {image_dir}")

        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        img_name = self.image_filenames[idx]
        img_path = os.path.join(self.image_dir, img_name)

        image = Image.open(img_path).convert("RGB")

        # Split paired images
        width, height = image.size
        input_image = image.crop((0, 0, width // 2, height))
        target_image = image.crop((width // 2, 0, width, height))

        if self.transform:
            input_image = self.transform(input_image)
            target_image = self.transform(target_image)

        return input_image, target_image

# Define transformations
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

image_dir = '/content/drive/MyDrive/Train/Imgs-20241210T155436Z-001/Imgs'  # Update with your path

dataset = Pix2PixDataset(image_dir=image_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# Visualize a batch
for inputs, targets in dataloader:
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))

    for i in range(4):
        axes[0, i].imshow((inputs[i].permute(1, 2, 0) * 0.5 + 0.5).clamp(0, 1))
        axes[0, i].set_title("Input")
        axes[0, i].axis('off')

        axes[1, i].imshow((targets[i].permute(1, 2, 0) * 0.5 + 0.5).clamp(0, 1))
        axes[1, i].set_title("Target")
        axes[1, i].axis('off')

    plt.show()
    break

import torch.nn as nn

# U-Net Generator
class UNetGenerator(nn.Module):
    def __init__(self):
        super(UNetGenerator, self).__init__()

        def down_block(in_channels, out_channels, normalize=True):
            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]
            if normalize:
                layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return nn.Sequential(*layers)

        def up_block(in_channels, out_channels, dropout=0.0):
            layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),
                      nn.BatchNorm2d(out_channels),
                      nn.ReLU(inplace=True)]
            if dropout:
                layers.append(nn.Dropout(dropout))
            return nn.Sequential(*layers)

        self.down1 = down_block(3, 64, normalize=False)
        self.down2 = down_block(64, 128)
        self.down3 = down_block(128, 256)
        self.down4 = down_block(256, 512)

        self.up1 = up_block(512, 256)
        self.up2 = up_block(512, 128)
        self.up3 = up_block(256, 64)
        self.up4 = nn.Sequential(nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),
                                 nn.Tanh())

    def forward(self, x):
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)

        u1 = self.up1(d4)
        u2 = self.up2(torch.cat([u1, d3], 1))
        u3 = self.up3(torch.cat([u2, d2], 1))
        return self.up4(torch.cat([u3, d1], 1))

generator = UNetGenerator().cuda() if torch.cuda.is_available() else UNetGenerator()

import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt
import os

# Define the loss function and optimizer
criterion_L1 = nn.L1Loss()
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# Ensure the generator is on the correct device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator.to(device)

# Create a directory to save models and visualizations
save_dir = "/content/drive/MyDrive/training_results"
os.makedirs(save_dir, exist_ok=True)

# Number of epochs
epochs = 50

# Training loop
for epoch in range(epochs):
    loop = tqdm(dataloader, desc=f"Epoch [{epoch+1}/{epochs}]")
    for inputs, targets in loop:
        inputs, targets = inputs.to(device), targets.to(device)

        # Zero the gradients
        optimizer_G.zero_grad()

        # Forward pass
        outputs = generator(inputs)
        loss = criterion_L1(outputs, targets)

        # Backward pass and optimize
        loss.backward()
        optimizer_G.step()

        # Update the progress bar
        loop.set_postfix(loss=loss.item())

    # Save the model and visualize the results every 10 epochs
    if (epoch + 1) % 10 == 0:
        # Save the model checkpoint
        model_save_path = os.path.join(save_dir, f"generator_epoch_{epoch+1}.pth")
        torch.save(generator.state_dict(), model_save_path)
        print(f"Model saved to {model_save_path}")

        # Visualize and save the results
        generator.eval()  # Set generator to evaluation mode
        with torch.no_grad():
            inputs, targets = next(iter(dataloader))  # Get a batch from the dataloader
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = generator(inputs)

            # Denormalize for display
            def denormalize(tensor):
                return (tensor * 0.5 + 0.5).clamp(0, 1)

            inputs_display = denormalize(inputs.cpu())
            targets_display = denormalize(targets.cpu())
            outputs_display = denormalize(outputs.cpu())

            # Plot and save the results
            fig, axes = plt.subplots(3, 4, figsize=(12, 9))
            for i in range(4):
                # Input images
                axes[0, i].imshow(inputs_display[i].permute(1, 2, 0))
                axes[0, i].set_title("Input")
                axes[0, i].axis('off')

                # Target images
                axes[1, i].imshow(targets_display[i].permute(1, 2, 0))
                axes[1, i].set_title("Target")
                axes[1, i].axis('off')

                # Generated images
                axes[2, i].imshow(outputs_display[i].permute(1, 2, 0))
                axes[2, i].set_title("Generated")
                axes[2, i].axis('off')

            plt.suptitle(f"Epoch {epoch+1}")
            results_path = os.path.join(save_dir, f"results_epoch_{epoch+1}.png")
            plt.savefig(results_path)
            plt.close(fig)
            print(f"Visualization saved to {results_path}")

        generator.train()  # Set generator back to training mode

# Save the model
torch.save(generator.state_dict(), "/content/drive/MyDrive/generator.pth")

# Load the model
generator.load_state_dict(torch.load("/content/drive/MyDrive/generator.pth"))

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
from google.colab import files
import io

# Define the Generator Class (Same as Used During Training)
class UNetGenerator(nn.Module):
    def __init__(self):
        super(UNetGenerator, self).__init__()

        def down_block(in_channels, out_channels, normalize=True):
            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]
            if normalize:
                layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return nn.Sequential(*layers)

        def up_block(in_channels, out_channels, dropout=0.0):
            layers = [
                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            ]
            if dropout:
                layers.append(nn.Dropout(dropout))
            return nn.Sequential(*layers)

        self.down1 = down_block(3, 64, normalize=False)
        self.down2 = down_block(64, 128)
        self.down3 = down_block(128, 256)
        self.down4 = down_block(256, 512)

        self.up1 = up_block(512, 256)
        self.up2 = up_block(512, 128)
        self.up3 = up_block(256, 64)
        self.up4 = nn.Sequential(nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),
                                 nn.Tanh())

    def forward(self, x):
        d1 = self.down1(x)
        d2 = self.down2(d1)
        d3 = self.down3(d2)
        d4 = self.down4(d3)

        u1 = self.up1(d4)
        u2 = self.up2(torch.cat([u1, d3], 1))
        u3 = self.up3(torch.cat([u2, d2], 1))
        return self.up4(torch.cat([u3, d1], 1))

# Load the trained generator
generator = UNetGenerator()
generator.load_state_dict(torch.load("/content/drive/MyDrive/generator.pth", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))
generator.eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator.to(device)

# Define the transformation
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
])

# Function to manually upload and process an image
def upload_and_process_image(generator, device):
    uploaded = files.upload()  # Upload the image file
    for filename in uploaded.keys():
        print(f"Processing image: {filename}")

        # Open the uploaded image
        image = Image.open(io.BytesIO(uploaded[filename])).convert("RGB")

        # Apply the transformation
        image_tensor = transform(image).unsqueeze(0).to(device)

        # Generate the output image
        with torch.no_grad():
            generated_tensor = generator(image_tensor)

        # Denormalize for display
        def denormalize(tensor):
            return (tensor * 0.5 + 0.5).clamp(0, 1)

        input_image_display = denormalize(image_tensor.squeeze(0)).permute(1, 2, 0).cpu().numpy()
        generated_image_display = denormalize(generated_tensor.squeeze(0)).permute(1, 2, 0).cpu().numpy()

        # Display the input and generated images
        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.title("Input Image")
        plt.imshow(input_image_display)
        plt.axis("off")

        plt.subplot(1, 2, 2)
        plt.title("Generated Image")
        plt.imshow(generated_image_display)
        plt.axis("off")

        plt.show()

# Call the function to upload and process an image
upload_and_process_image(generator, device)

# import torch
# from torchvision import transforms
# from PIL import Image
# import matplotlib.pyplot as plt
# import os

# # Define the Generator class (same as used during training)
# class UNetGenerator(nn.Module):
#     def __init__(self):
#         super(UNetGenerator, self).__init__()

#         def down_block(in_channels, out_channels, normalize=True):
#             layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)]
#             if normalize:
#                 layers.append(nn.BatchNorm2d(out_channels))
#             layers.append(nn.LeakyReLU(0.2, inplace=True))
#             return nn.Sequential(*layers)

#         def up_block(in_channels, out_channels, dropout=0.0):
#             layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),
#                       nn.BatchNorm2d(out_channels),
#                       nn.ReLU(inplace=True)]
#             if dropout:
#                 layers.append(nn.Dropout(dropout))
#             return nn.Sequential(*layers)

#         self.down1 = down_block(3, 64, normalize=False)
#         self.down2 = down_block(64, 128)
#         self.down3 = down_block(128, 256)
#         self.down4 = down_block(256, 512)

#         self.up1 = up_block(512, 256)
#         self.up2 = up_block(512, 128)
#         self.up3 = up_block(256, 64)
#         self.up4 = nn.Sequential(nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),
#                                  nn.Tanh())

#     def forward(self, x):
#         d1 = self.down1(x)
#         d2 = self.down2(d1)
#         d3 = self.down3(d2)
#         d4 = self.down4(d3)

#         u1 = self.up1(d4)
#         u2 = self.up2(torch.cat([u1, d3], 1))
#         u3 = self.up3(torch.cat([u2, d2], 1))
#         return self.up4(torch.cat([u3, d1], 1))

# # Load the trained model weights
# generator = UNetGenerator()
# generator.load_state_dict(torch.load("/content/drive/MyDrive/generator.pth", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))
# generator.eval()

# # Move the model to GPU if available
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# generator.to(device)

# # Path to a test image (update this path accordingly)
# test_image_path = '/content/drive/MyDrive/SINET/TestDataset-20241211T025305Z-001/TestDataset/CAMO/Imgs/camourflage_00018.jpg'  # Update with the actual path

# # Define the transformation for the test image
# transform = transforms.Compose([
#     transforms.Resize((256, 256)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
# ])

# # Load and preprocess the test image
# test_image = Image.open(test_image_path).convert("RGB")
# test_tensor = transform(test_image).unsqueeze(0).to(device)  # Add batch dimension

# # Generate the output image
# with torch.no_grad():
#     generated_tensor = generator(test_tensor)

# # Denormalize the tensors for display
# def denormalize(tensor):
#     return (tensor * 0.5 + 0.5).clamp(0, 1)

# # Convert tensors to images for display
# input_image_display = denormalize(test_tensor.squeeze(0)).permute(1, 2, 0).cpu().numpy()
# generated_image_display = denormalize(generated_tensor.squeeze(0)).permute(1, 2, 0).cpu().numpy()

# # Display the input and generated images
# plt.figure(figsize=(12, 6))

# plt.subplot(1, 2, 1)
# plt.title("Input Image (Non-Camouflaged)")
# plt.imshow(input_image_display)
# plt.axis("off")

# plt.subplot(1, 2, 2)
# plt.title("Generated Image (Camouflaged)")
# plt.imshow(generated_image_display)
# plt.axis("off")

# plt.show()

